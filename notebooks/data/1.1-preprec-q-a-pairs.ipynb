{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of question-answering pairs\n",
    "\n",
    "## Description\n",
    "The the scores distributions in different filtering ways, output json file at the end.\n",
    "\n",
    "## Tasks\n",
    "\n",
    "1. Check answers count for each question\n",
    "\n",
    "2. Filter answers with blocks of code\n",
    "\n",
    "3. Check answers count for each question again\n",
    "\n",
    "4. Score distributions and filter questions with less than 3 answers\n",
    "\n",
    "5. Score distribution\n",
    "\n",
    "6. JSON output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from os.path import join as opj\n",
    "import plotly.figure_factory as ff\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'D:\\CQA_RLHF\\data\\interim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_a_df = pd.read_csv(opj(data_path, 'question_answers.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_a_df['A_Score_norm_ans_count'] = q_a_df.A_Score / q_a_df.AnswerCount\n",
    "# q_a_df['A_Score_norm_views_count'] = q_a_df.A_Score / q_a_df.ViewCount"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers without blocks of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_column(df, column_name, text_to_filter, regex=False):\n",
    "    before_filtering = len(df)\n",
    "    df = df[\n",
    "        ~df[f\"{column_name}\"].str.contains(f\"{text_to_filter}\", na=False, regex=regex)\n",
    "    ]\n",
    "    after_filtering = len(df)\n",
    "    print(f\"Deleted {before_filtering-after_filtering} rows\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_a_df_no_code = filter_column(q_a_df, 'A_Body', \"</code></pre>\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count of answers to each question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match for each questions in a row count of anaswers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_a_df_no_code['count_available_anaswers'] = q_a_df_no_code['Q_Id'].map(q_a_df_no_code['Q_Id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('1 answer available:', len(q_a_df_no_code.loc[q_a_df_no_code['count_available_anaswers'] == 1]))\n",
    "print('More than 1 answer available:', len(q_a_df_no_code.loc[q_a_df_no_code['count_available_anaswers'] != 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_a_scaler = preprocessing.MaxAbsScaler()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform without outliers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтрация выбросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_outliers_iqr(data, column):\n",
    "#     q1, q3 = data[column].quantile([0.15, 0.75])\n",
    "#     iqr = q3 - q1\n",
    "#     lower_bound = q1 - (1.5 * iqr)\n",
    "#     upper_bound = q3 + (1.5 * iqr)\n",
    "#     return (\n",
    "#         data[column][(data[column] > lower_bound) & (data[column] < upper_bound)],\n",
    "#         data[column][data[column] <= lower_bound],\n",
    "#         data[column][data[column] >= upper_bound],\n",
    "#     )\n",
    "\n",
    "\n",
    "# def filter_and_transform(data, column, scaler, new_col_name):\n",
    "#     filtered_data, lower_outliers, upper_outliers = filter_outliers_iqr(data, column)\n",
    "\n",
    "#     print(len(filtered_data), len(lower_outliers), len(upper_outliers))\n",
    "\n",
    "#     filtered_scaled_data = scaler.fit_transform(filtered_data.values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "#     filtered_scaled_data = pd.Series(filtered_scaled_data, index=filtered_data.index)\n",
    "\n",
    "#     transformed_series = pd.concat(\n",
    "#         [filtered_scaled_data, lower_outliers, upper_outliers], axis=0\n",
    "#     )\n",
    "#     transformed_series.name = new_col_name\n",
    "\n",
    "#     return data.join(transformed_series, how=\"left\", on=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_outliers_iqr(data, column):\n",
    "    q1, q3 = data[column].quantile([0.15, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (1.5 * iqr)\n",
    "    upper_bound = q3 + (1.5 * iqr)\n",
    "\n",
    "    return (\n",
    "        data[column][(data[column] > lower_bound) & (data[column] < upper_bound)],\n",
    "        data[column][data[column] <= lower_bound],\n",
    "        data[column][data[column] >= upper_bound],\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_and_transform(data, column, scaler, new_col_name):\n",
    "    filtered_data, lower_outliers, upper_outliers = filter_outliers_iqr(data, column)\n",
    "    lower_outliers.values[:] = -1\n",
    "    upper_outliers.values[:] = 1\n",
    "\n",
    "    print(len(filtered_data), len(lower_outliers), len(upper_outliers))\n",
    "\n",
    "    filtered_scaled_data = scaler.fit_transform(filtered_data.values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "    filtered_scaled_data = pd.Series(filtered_scaled_data, index=filtered_data.index)\n",
    "\n",
    "    transformed_series = pd.concat(\n",
    "        [filtered_scaled_data, lower_outliers, upper_outliers], axis=0\n",
    "    )\n",
    "    transformed_series.name = new_col_name\n",
    "\n",
    "    return data.join(transformed_series, how=\"left\", on=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_a_df_no_code = filter_and_transform(q_a_df_no_code, 'A_Score_norm_ans_count', m_a_scaler, 'A_Score_norm_ans_count_max_abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_transform_sep(data, column, scaler, new_col_name):\n",
    "    filtered_data, lower_outliers, upper_outliers = filter_outliers_iqr(data, column)\n",
    "    lower_outliers.values[:] = -1\n",
    "    upper_outliers.values[:] = 1\n",
    "\n",
    "    print(len(filtered_data), len(lower_outliers), len(upper_outliers))\n",
    "\n",
    "    pos = filtered_data[filtered_data[:] >= 0]\n",
    "    neg = filtered_data[filtered_data[:] < 0]\n",
    "\n",
    "    pos_filtered_scaled_data = scaler.fit_transform(pos.values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "    neg_filtered_scaled_data = scaler.fit_transform(neg.values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "\n",
    "    neg_filtered_scaled_data = pd.Series(neg_filtered_scaled_data, index=neg.index)\n",
    "    pos_filtered_scaled_data = pd.Series(pos_filtered_scaled_data, index=pos.index)\n",
    "\n",
    "    transformed_series = pd.concat(\n",
    "        [pos_filtered_scaled_data, neg_filtered_scaled_data, lower_outliers, upper_outliers], axis=0\n",
    "    )\n",
    "    transformed_series.name = new_col_name\n",
    "\n",
    "    return data.join(transformed_series, how=\"left\", on=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60211 128 5514\n"
     ]
    }
   ],
   "source": [
    "q_a_df_no_code = filter_and_transform_sep(q_a_df_no_code, 'A_Score_norm_ans_count', m_a_scaler, 'A_Score_norm_ans_count_max_abs')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменить Score Accepted Asnwers to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_answers_indexes = q_a_df_no_code[\n",
    "    q_a_df_no_code[\"A_Id\"].isin(q_a_df_no_code[\"AcceptedAnswerId\"].unique())\n",
    "].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_a_df_no_code.loc[\n",
    "#     accepted_answers_indexes, [\"A_Score_norm_ans_count_max_abs\"]\n",
    "# ] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_a_df_no_code['A_Score_norm_ans_count_max_abs_tanh'] = np.tanh(q_a_df_no_code.A_Score_norm_ans_count_max_abs)\n",
    "q_a_df_no_code['A_Score_norm_ans_count_tanh'] = np.tanh(q_a_df_no_code.A_Score_norm_ans_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_a_df_no_code.loc[\n",
    "    accepted_answers_indexes, [\"A_Score_norm_ans_count_max_abs_tanh\", \"A_Score_norm_ans_count_tanh\"]\n",
    "] = 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Предполагая, что у вас есть DataFrame df с колонками 'col1', 'col2', 'col3'\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 6))\n",
    "\n",
    "sns.kdeplot(data=q_a_df_no_code.A_Score_norm_ans_count, ax=axs[0])\n",
    "sns.kdeplot(data=q_a_df_no_code.A_Score_norm_ans_count_max_abs_tanh, ax=axs[1])\n",
    "sns.kdeplot(data=q_a_df_no_code.A_Score_norm_ans_count_max_abs, ax=axs[2])\n",
    "sns.kdeplot(data=q_a_df_no_code.A_Score_norm_ans_count_tanh, ax=axs[3])\n",
    "# sns.histplot(data=df, x=\"col3\", ax=axs[2], kde=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просмотр KDE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use $log_2$ for scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_answers_indexes = q_a_df_no_code[\n",
    "    q_a_df_no_code[\"A_Id\"].isin(q_a_df_no_code[\"AcceptedAnswerId\"].unique())\n",
    "].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.log2(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_scores = []\n",
    "for i in q_a_df_no_code['A_Score']:\n",
    "    if i >= 0:\n",
    "        log_scores.append(round(np.log(i+1)))\n",
    "    else:\n",
    "        log_scores.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(log_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_a_df_no_code['Log_scores'] = log_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_a_df_no_code['Log_scores'] = q_a_df_no_code['Log_scores'] + q_a_df_no_code['AcceptedAnswer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r'D:\\CQA_RLHF\\data\\processed\\log_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_a_df_no_code['AcceptedAnswer'] = q_a_df_no_code['AcceptedAnswerId'] == q_a_df_no_code['A_Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = q_a_df_no_code[['Q_CreationDate', 'Q_Title', 'Q_Body', 'A_Body', 'A_Score_norm_ans_count_max_abs', 'AcceptedAnswer', 'count_available_anaswers']]\n",
    "# data = q_a_df_no_code[['Q_CreationDate', 'Q_Title', 'Q_Body', 'A_Body', 'A_Score_norm_ans_count_max_abs_tanh', 'AcceptedAnswer', 'count_available_anaswers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Q_Title'] = data['Q_Title'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text().strip())\n",
    "data['Q_Body'] = data['Q_Body'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text().strip())\n",
    "data['A_Body'] = data['A_Body'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(\n",
    "    columns={\n",
    "        \"Q_Title\": \"Title\",\n",
    "        \"Q_Body\": \"Question\",\n",
    "        \"A_Body\": \"Answer\",\n",
    "        # \"A_Score_norm_ans_count_max_abs_tanh\": \"Score\",\n",
    "        'A_Score_norm_ans_count_max_abs': \"Score\",\n",
    "        \"AcceptedAnswer\": \"Is_accepted\",\n",
    "        \"count_available_anaswers\": \"N_answers\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values('Q_CreationDate', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Q_Id'] = data.groupby('Q_CreationDate').ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'D:\\CQA_RLHF\\data\\processed\\tanh_score\\1.0-all-data-tanh_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data[:-3000]\n",
    "val_df = data[-3000:-2000]\n",
    "test_df = data[-2000:]\n",
    "# Convert each set to a dictionary\n",
    "train_dict = train_df.to_dict(orient='records')\n",
    "val_dict = val_df.to_dict(orient='records')\n",
    "test_dict = test_df.to_dict(orient='records')\n",
    "\n",
    "# Combine the dictionaries into a list of dictionaries\n",
    "data_to_save = {'train': train_dict, 'val': val_dict, 'test': test_dict}\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "with open(opj(save_path, '1.0-data-div-ans-sep.json'), 'w') as f:\n",
    "    json.dump(data_to_save, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(opj(save_path, '1.0-data-div-ans-sep.json'), 'r') as f:\n",
    "    pairs = json.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
